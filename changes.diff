commit cbca9319c92fd24d62d4ff0045f7871048c3da63
Author: Your Name <you@example.com>
Date:   Wed Dec 17 16:29:31 2025 -0800

    c

diff --git a/Archiceture.md b/Archiceture.md
index aa126c8..de9de17 100644
--- a/Archiceture.md
+++ b/Archiceture.md
@@ -54,11 +54,16 @@ tests/
 
 ```mermaid
 flowchart TB
-  CLI[cli/main.py<br/>parses args, builds DecisionTask] --> FW[frameworks/*<br/>council/dxo/ensemble]
-  FW --> INV[models.py<br/>invoke_model(model_key, messages)]
-  INV --> PROV[providers/local.py<br/>call_local_model()]
-  PROV --> VLLM[(vLLM server<br/>/v1/chat/completions)]
-  FW --> TYPES[types.py<br/>DecisionTask/Result, AgentMessage, ChatMessage]
+  CLI["CLI (agentic.cli.main)"]
+  FW["Frameworks (council / dxo / ensemble)"]
+  INV["Model Dispatcher (invoke_model)"]
+  PROV["Local Provider"]
+  VLLM["vLLM Server"]
+
+  CLI --> FW
+  FW --> INV
+  INV --> PROV
+  PROV --> VLLM
 ```
 
 ```mermaid
diff --git a/PROJECT_NORTH_STAR.MD b/PROJECT_NORTH_STAR.MD
index e69de29..adc6420 100644
--- a/PROJECT_NORTH_STAR.MD
+++ b/PROJECT_NORTH_STAR.MD
@@ -0,0 +1,144 @@
+Agentic Code Ensemble Project North Star
+Mission
+
+Build a local-first, production-shaped agentic system in Python that can plan, generate, review, and iterate on code changes using a role-specialized agent ensemble and a Chair synthesizer. Start simple, stay rigorous, and grow into MCP-based tooling.
+
+Current Focus
+
+Implement an ensemble of role-specialized agents:
+
+PM → requirements + acceptance criteria artifact
+
+Dev → implementation plan (and later patch) artifact
+
+SRE/DevOps → deploy/ops constraints + runbook artifact
+
+Security → threat review + abuse cases artifact
+
+Reviewer → critique + minimal-diff + test strategy artifact
+
+Chair → synthesizes all artifacts into a final plan (then later a unified diff patch)
+
+We distinguish:
+
+Role-collaboration (one coherent solution via perspectives)
+
+Proposal ensemble (multiple competing candidate solutions, scored/merged)
+We start roles-first, then add proposal ensembles later.
+
+Principles
+
+Local-first: default to local models via vLLM; avoid personal billing risk.
+
+Good software engineering:
+
+src/ layout (no magic imports)
+
+typed dataclasses / clear schemas
+
+small functions, testability, separation of concerns
+
+unit tests that mock model calls
+
+Artifacts > vibes: agents produce typed JSON artifacts, not just prose.
+
+Traceability: store per-role outputs + critiques + chair synthesis in a structured DecisionResult.
+
+Minimal drift: each milestone should produce a runnable CLI + tests.
+
+Roadmap Stages
+Stage 1 — Local agentic ensemble (now)
+
+Provider: vLLM OpenAI-compatible local server
+
+Framework: Roles-first (PM/Dev/SRE/Sec/Reviewer → Chair)
+
+Outputs: structured artifacts + final plan
+
+CLI: run a task, print final plan + optionally dump JSON
+
+Stage 2 — Add MCP properly
+
+Wrap model invocation behind an MCP tool (e.g., invoke_model)
+
+Add additional MCP tools (filesystem, git diff, test runner hooks later)
+
+Orchestrator calls tools through MCP, not direct HTTP
+
+Stage 3 — Patch generation + review loop
+
+Inputs: repo snapshot / file list / issue description
+
+Agents propose:
+
+tests-first plan
+
+minimal diffs
+
+Chair outputs unified diff + test commands
+
+Add iterative loop: run tests → feed failures → refine patch
+
+Stage 4 — Broader AI mastery integration
+
+While staying on-task, opportunistically build understanding of:
+
+tokens, context windows, temperature/top_p (sampling)
+
+evals over time (regression suites for agent quality)
+
+transformers + math foundations (as separate learning modules)
+
+Dawnwalker concepts as inspiration, not scope creep
+
+“Don’t get distracted” guardrails
+
+If a topic doesn’t directly help one of these, park it:
+
+Role artifact schemas
+
+Orchestration flow (initial → critique → synthesis)
+
+Model routing (small for drafts, large for chair)
+
+Reliable testing, logging, and packaging
+
+MCP tool boundaries
+
+If we detour into deep theory (transformers/math), we do it in separate exercises, not by bloating the core repo.
+
+Sampling & cost knobs to learn (apply consistently)
+
+max_tokens: cap output size per role to avoid rambling
+
+temperature:
+
+low (0.1–0.3) for reviewer/security consistency
+
+medium (0.5–0.8) for ideation / multiple options
+
+chair often low-medium for stable synthesis
+
+top_p: alternative to temperature; keep simple early
+
+routing:
+
+small model for drafts + critiques
+
+large model for chair synthesis
+
+Definition of Done (for Stage 1)
+
+python -m agentic.cli.main roles "<question>" runs end-to-end locally
+
+Produces:
+
+per-role JSON artifacts
+
+critiques
+
+chair synthesis plan
+
+Tests run without a local model server (provider calls mocked)
+
+Repo uses src/ layout
\ No newline at end of file
diff --git a/README.md b/README.md
index e69de29..99f1089 100644
--- a/README.md
+++ b/README.md
@@ -0,0 +1 @@
+# todo
\ No newline at end of file
diff --git a/src/agentic/frameworks/council.py b/src/agentic/frameworks/council.py
index e69de29..4951891 100644
--- a/src/agentic/frameworks/council.py
+++ b/src/agentic/frameworks/council.py
@@ -0,0 +1,64 @@
+import asyncio
+from typing import List, Dict, Any
+from ..types import (
+    DecisionTask,
+    DecisionResult,
+    ChatMessage,
+    AgentMessage,
+)
+from ..models import invoke_model
+
+
+async def run_council(task: DecisionTask) -> DecisionResult:
+    cfg = task.framework_config
+    members: List[Dict[str, str]] = cfg["members"]
+    chair_model: str = cfg["chair"]
+
+    async def call_member(member: Dict[str, str]) -> AgentMessage:
+        content = await invoke_model(
+            member["model"],
+            [ChatMessage(role="user", content=task.question)],
+        )
+        return AgentMessage(
+            role_id=member["id"],
+            model_key=member["model"],
+            stage="initial",
+            content=content,
+        )
+
+    member_msgs = await asyncio.gather(*[call_member(m) for m in members])
+
+    chair_prompt = build_chair_prompt(task.question, member_msgs)
+
+    chair_answer = await invoke_model(
+        chair_model,
+        [ChatMessage(role="user", content=chair_prompt)],
+    )
+
+    messages = member_msgs + [
+        AgentMessage(
+            role_id="chair",
+            model_key=chair_model,
+            stage="synthesis",
+            content=chair_answer,
+        )
+    ]
+
+    return DecisionResult(
+        task_id=task.id,
+        final_answer=chair_answer,
+        messages=messages,
+        metadata={"framework": "council"},
+    )
+
+
+def build_chair_prompt(question: str, members: List[AgentMessage]) -> str:
+    lines = [
+        "You are the chair of an expert council.",
+        "Summarize consensus, disagreements, and give a final recommendation.\n",
+        f"Question:\n{question}\n",
+        "Expert inputs:\n",
+    ]
+    for m in members:
+        lines.append(f"{m.role_id}:\n{m.content}\n")
+    return "\n".join(lines)
diff --git a/src/agentic/frameworks/ensemble.py b/src/agentic/frameworks/ensemble.py
index e69de29..1a44a86 100644
--- a/src/agentic/frameworks/ensemble.py
+++ b/src/agentic/frameworks/ensemble.py
@@ -0,0 +1,51 @@
+import asyncio
+from typing import List
+from ..types import (
+    DecisionTask,
+    DecisionResult,
+    ChatMessage,
+    AgentMessage,
+)
+from ..models import invoke_model
+
+
+async def run_ensemble(task: DecisionTask) -> DecisionResult:
+    cfg = task.framework_config
+    models: List[str] = cfg["models"]
+    aggregator: str = cfg["aggregator"]
+
+    async def call_model(idx: int, model: str) -> AgentMessage:
+        content = await invoke_model(
+            model,
+            [ChatMessage(role="user", content=task.question)],
+        )
+        return AgentMessage(
+            role_id=f"agent_{idx}",
+            model_key=model,
+            stage="initial",
+            content=content,
+        )
+
+    agent_msgs = await asyncio.gather(
+        *[call_model(i, m) for i, m in enumerate(models)]
+    )
+
+    agg_prompt = "Aggregate the following anonymous answers:\n\n"
+    for m in agent_msgs:
+        agg_prompt += f"{m.role_id}:\n{m.content}\n\n"
+
+    final = await invoke_model(
+        aggregator,
+        [ChatMessage(role="user", content=agg_prompt)],
+    )
+
+    messages = agent_msgs + [
+        AgentMessage("aggregator", aggregator, "synthesis", final)
+    ]
+
+    return DecisionResult(
+        task_id=task.id,
+        final_answer=final,
+        messages=messages,
+        metadata={"framework": "ensemble"},
+    )
